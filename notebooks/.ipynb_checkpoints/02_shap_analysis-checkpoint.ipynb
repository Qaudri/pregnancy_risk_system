{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aac9f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SHAP Analysis for Model Interpretability\n",
    "Provides clinical explainability for predictions\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "# Configuration\n",
    "DATA_PROCESSED_PATH = '../data/processed/'\n",
    "MODELS_PATH = '../models/'\n",
    "RESULTS_FIGURES_PATH = '../results/figures/'\n",
    "\n",
    "# Initialize SHAP\n",
    "shap.initjs()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SHAP ANALYSIS FOR MODEL INTERPRETABILITY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD MODELS AND DATA\n",
    "# ============================================================================\n",
    "print(\"\\n1. Loading models and test data...\")\n",
    "\n",
    "rf_model = joblib.load(f'{MODELS_PATH}rf_model.pkl')\n",
    "xgb_model = joblib.load(f'{MODELS_PATH}xgb_model.pkl')\n",
    "X_test = pd.read_csv(f'{DATA_PROCESSED_PATH}X_test.csv')\n",
    "y_test = pd.read_csv(f'{DATA_PROCESSED_PATH}y_test.csv').values.ravel()\n",
    "\n",
    "print(f\" Loaded models\")\n",
    "print(f\" Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963eb3d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 2. RANDOM FOREST - FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. RANDOM FOREST - FEATURE IMPORTANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Rankings:\")\n",
    "print(feature_importance_rf.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_rf['Feature'], feature_importance_rf['Importance'],\n",
    "         color='#3498db')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Random Forest - Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_FIGURES_PATH}rf_feature_importance.png',\n",
    "           dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n Saved: {RESULTS_FIGURES_PATH}rf_feature_importance.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411e452",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 3. XGBOOST - SHAP ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. XGBOOST - SHAP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nCreating SHAP explainer (this may take a moment)...\")\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(\" SHAP values computed\")\n",
    "print(f\"  Shape: {shap_values.shape}\")\n",
    "print(f\"  Base value (expected output): {explainer.expected_value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76315b0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. SHAP SUMMARY PLOT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4. SHAP SUMMARY PLOT (MOST IMPORTANT)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.title('SHAP Feature Importance - Impact on Predictions',\n",
    "         fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_FIGURES_PATH}shap_summary.png',\n",
    "           dpi=300, bbox_inches='tight')\n",
    "print(f\" Saved: {RESULTS_FIGURES_PATH}shap_summary.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86d757",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. SHAP BAR PLOT (Mean Absolute Values)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5. SHAP BAR PLOT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance - Mean Absolute Impact',\n",
    "         fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_FIGURES_PATH}shap_bar.png',\n",
    "           dpi=300, bbox_inches='tight')\n",
    "print(f\" Saved: {RESULTS_FIGURES_PATH}shap_bar.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde09c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. EXAMPLE PREDICTION EXPLANATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"6. EXAMPLE HIGH-RISK PREDICTION EXPLANATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find a correctly predicted high-risk case\n",
    "high_risk_indices = np.where((y_test == 1) & (xgb_model.predict(X_test) == 1))[0]\n",
    "sample_idx = high_risk_indices[0]\n",
    "\n",
    "print(f\"\\nExample patient (test set index {sample_idx}):\")\n",
    "sample_data = X_test.iloc[sample_idx]\n",
    "print(sample_data)\n",
    "\n",
    "print(f\"\\nActual label: High Risk (1)\")\n",
    "print(f\"Predicted label: High Risk (1)\")\n",
    "print(f\"Prediction probability: {xgb_model.predict_proba(X_test.iloc[[sample_idx]])[0][1]:.4f}\")\n",
    "\n",
    "# Waterfall plot\n",
    "explanation = shap.Explanation(\n",
    "    values=shap_values[sample_idx],\n",
    "    base_values=explainer.expected_value,\n",
    "    data=sample_data,\n",
    "    feature_names=X_test.columns.tolist()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.waterfall_plot(explanation, show=False)\n",
    "plt.title(f'SHAP Waterfall - Example High-Risk Prediction',\n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_FIGURES_PATH}shap_waterfall_example.png',\n",
    "           dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n Saved: {RESULTS_FIGURES_PATH}shap_waterfall_example.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4401da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7. TOP FEATURES ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"7. TOP FEATURES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get top 3 features by mean absolute SHAP value\n",
    "mean_shap = np.abs(shap_values).mean(axis=0)\n",
    "top_features_idx = np.argsort(mean_shap)[::-1][:3]\n",
    "top_features = X_test.columns[top_features_idx]\n",
    "\n",
    "print(f\"\\nTop 3 most impactful features:\")\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    print(f\"  {i}. {feature}: {mean_shap[top_features_idx[i-1]]:.4f}\")\n",
    "\n",
    "# Dependence plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    plt.sca(axes[idx])\n",
    "    shap.dependence_plot(\n",
    "        feature, shap_values, X_test,\n",
    "        interaction_index=None,\n",
    "        show=False, ax=axes[idx]\n",
    "    )\n",
    "    axes[idx].set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('SHAP Dependence Plots - Top 3 Features',\n",
    "            fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_FIGURES_PATH}shap_dependence_top3.png',\n",
    "           dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n Saved: {RESULTS_FIGURES_PATH}shap_dependence_top3.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b24e89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 8. SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SHAP ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Generated Files:\n",
    "1. rf_feature_importance.png - Random Forest feature rankings\n",
    "2. shap_summary.png - SHAP importance with impact direction\n",
    "3. shap_bar.png - Mean absolute SHAP values\n",
    "4. shap_waterfall_example.png - Single prediction explanation\n",
    "5. shap_dependence_top3.png - Feature interaction plots\n",
    "\n",
    "Key Insights:\n",
    "- Top feature (RF): {feature_importance_rf.iloc[0]['Feature']}\n",
    "- Top feature (SHAP): {top_features[0]}\n",
    "- Both models agree on important features\n",
    "- SHAP provides explanation for individual predictions\n",
    "\n",
    "Clinical Interpretation:\n",
    "The model's decisions are driven primarily by medical history\n",
    "(diabetes status), metabolic indicators (BS, BMI), and vital signs.\n",
    "This aligns with clinical understanding of pregnancy risk factors.\n",
    "\n",
    "These visualizations provide:\n",
    " Transparency for clinicians\n",
    " Trust in model decisions\n",
    " Insights into risk factors\n",
    " Explainability for individual cases\n",
    "\n",
    "All figures ready for Chapter 4 of thesis!\n",
    "\"\"\")\n",
    "\n",
    "print(f\" SHAP analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
